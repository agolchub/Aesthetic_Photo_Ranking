
CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.
To initialize your shell, run

    $ conda init <SHELL_NAME>

Currently supported shells are:
  - bash
  - fish
  - tcsh
  - xonsh
  - zsh
  - powershell

See 'conda init --help' for more information and options.

IMPORTANT: You may need to close and restart your shell after running 'conda init'.


Mon Oct 25 17:18:17 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  A100-PCIE-40GB      Off  | 00000000:21:00.0 Off |                    0 |
| N/A   38C    P0    40W / 250W |      0MiB / 40536MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
2021-10-25 17:18:30.137293: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-10-25 17:18:30.975454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38426 MB memory:  -> device: 0, name: A100-PCIE-40GB, pci bus id: 0000:21:00.0, compute capability: 8.0
/mnt/beegfs/home/agolchub/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  warnings.warn(
Input file is " 
Output file is " agnet.model
Image path is " 
--------------------


Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 1024, 680, 3 0                                            
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 298, 297, 32) 1115168     input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 298, 297, 32) 128         conv2d[0][0]                     
__________________________________________________________________________________________________
dropout (Dropout)               (None, 298, 297, 32) 0           batch_normalization[0][0]        
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 117, 116, 64) 8921152     dropout[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 117, 116, 64) 256         conv2d_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 117, 116, 64) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 51, 51, 128)  2097280     dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 51, 51, 128)  512         conv2d_2[0][0]                   
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 51, 51, 128)  0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 23, 23, 256)  1605888     dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 23, 23, 256)  1024        conv2d_3[0][0]                   
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 23, 23, 256)  0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 21, 21, 512)  1180160     dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 21, 21, 512)  2048        conv2d_4[0][0]                   
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 21, 21, 512)  0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 20, 20, 256)  524544      dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 20, 20, 256)  1024        conv2d_5[0][0]                   
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 20, 20, 256)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 19, 19, 128)  131200      dropout_5[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 19, 19, 128)  512         conv2d_6[0][0]                   
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 19, 19, 128)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 18, 18, 64)   32832       dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 18, 18, 64)   256         conv2d_7[0][0]                   
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 18, 18, 64)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 17, 17, 64)   16448       dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 17, 17, 64)   256         conv2d_8[0][0]                   
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 17, 17, 64)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
flatten (Flatten)               (None, 2832192)      0           dropout[0][0]                    
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 868608)       0           dropout_1[0][0]                  
__________________________________________________________________________________________________
flatten_2 (Flatten)             (None, 332928)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
flatten_3 (Flatten)             (None, 135424)       0           dropout_3[0][0]                  
__________________________________________________________________________________________________
flatten_4 (Flatten)             (None, 225792)       0           dropout_4[0][0]                  
__________________________________________________________________________________________________
flatten_5 (Flatten)             (None, 102400)       0           dropout_5[0][0]                  
__________________________________________________________________________________________________
flatten_6 (Flatten)             (None, 46208)        0           dropout_6[0][0]                  
__________________________________________________________________________________________________
flatten_7 (Flatten)             (None, 20736)        0           dropout_7[0][0]                  
__________________________________________________________________________________________________
flatten_8 (Flatten)             (None, 18496)        0           dropout_8[0][0]                  
__________________________________________________________________________________________________
dense (Dense)                   (None, 5)            14160965    flatten[0][0]                    
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 5)            4343045     flatten_1[0][0]                  
__________________________________________________________________________________________________
/mnt/beegfs/home/agolchub/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.
  warnings.warn('`Model.fit_generator` is deprecated and '
2021-10-25 17:18:33.055449: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
2021-10-25 17:18:36.981783: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8201
2021-10-25 17:18:38.886433: W tensorflow/stream_executor/gpu/asm_compiler.cc:77] Couldn't get ptxas version string: Internal: Running ptxas --version returned 32512
2021-10-25 17:18:38.912859: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 32512, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
2021-10-25 17:18:46.492508: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
dense_2 (Dense)                 (None, 5)            1664645     flatten_2[0][0]                  
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 5)            677125      flatten_3[0][0]                  
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 5)            1128965     flatten_4[0][0]                  
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 5)            512005      flatten_5[0][0]                  
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 5)            231045      flatten_6[0][0]                  
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 5)            103685      flatten_7[0][0]                  
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 128)          2367616     flatten_8[0][0]                  
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 168)          0           dense[0][0]                      
                                                                 dense_1[0][0]                    
                                                                 dense_2[0][0]                    
                                                                 dense_3[0][0]                    
                                                                 dense_4[0][0]                    
                                                                 dense_5[0][0]                    
                                                                 dense_6[0][0]                    
                                                                 dense_7[0][0]                    
                                                                 dense_8[0][0]                    
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 256)          43264       concatenate[0][0]                
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 256)          0           dense_9[0][0]                    
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 128)          32896       dropout_9[0][0]                  
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 128)          0           dense_10[0][0]                   
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 1)            129         dropout_10[0][0]                 
==================================================================================================
Total params: 40,896,073
Trainable params: 40,893,065
Non-trainable params: 3,008
__________________________________________________________________________________________________
None
Epoch 1/100
  1/119 [..............................] - ETA: 42:42 - loss: 7.4961  2/119 [..............................] - ETA: 1:12 - loss: 4.8651   3/119 [..............................] - ETA: 2:01 - loss: 4.5555  4/119 [>.............................] - ETA: 2:24 - loss: 4.6677  5/119 [>.............................] - ETA: 2:35 - loss: 4.4561  6/119 [>.............................] - ETA: 2:43 - loss: 4.6337  7/119 [>.............................] - ETA: 2:41 - loss: 4.8467  8/119 [=>............................] - ETA: 2:38 - loss: 4.9007  9/119 [=>............................] - ETA: 2:39 - loss: 4.7829 10/119 [=>............................] - ETA: 2:38 - loss: 5.2703 11/119 [=>............................] - ETA: 2:37 - loss: 5.0911 12/119 [==>...........................] - ETA: 2:37 - loss: 4.9078 13/119 [==>...........................] - ETA: 2:38 - loss: 5.0318 14/119 [==>...........................] - ETA: 2:38 - loss: 4.9791 15/119 [==>...........................] - ETA: 2:38 - loss: 4.9436 16/119 [===>..........................] - ETA: 2:37 - loss: 4.9149 17/119 [===>..........................] - ETA: 2:34 - loss: 4.9620 18/119 [===>..........................] - ETA: 2:33 - loss: 5.0313 19/119 [===>..........................] - ETA: 2:31 - loss: 5.0483 20/119 [====>.........................] - ETA: 2:30 - loss: 5.0601 21/119 [====>.........................] - ETA: 2:29 - loss: 5.0969 22/119 [====>.........................] - ETA: 2:28 - loss: 5.0047 23/119 [====>.........................] - ETA: 2:27 - loss: 4.9350 24/119 [=====>........................] - ETA: 2:25 - loss: 4.9699 25/119 [=====>........................] - ETA: 2:23 - loss: 4.9352 26/119 [=====>........................] - ETA: 2:20 - loss: 4.9066 27/119 [=====>........................] - ETA: 2:19 - loss: 4.8362 28/119 [======>.......................] - ETA: 2:18 - loss: 4.8228 29/119 [======>.......................] - ETA: 2:16 - loss: 4.8519 30/119 [======>.......................] - ETA: 2:14 - loss: 4.8202 31/119 [======>.......................] - ETA: 2:12 - loss: 4.7465 32/119 [=======>......................] - ETA: 2:11 - loss: 4.7883 33/119 [=======>......................] - ETA: 2:09 - loss: 4.7773 34/119 [=======>......................] - ETA: 2:07 - loss: 4.7818 35/119 [=======>......................] - ETA: 2:06 - loss: 4.7565 36/119 [========>.....................] - ETA: 2:05 - loss: 4.7610 37/119 [========>.....................] - ETA: 2:03 - loss: 4.7202 38/119 [========>.....................] - ETA: 2:02 - loss: 4.7289 39/119 [========>.....................] - ETA: 2:00 - loss: 4.7837 40/119 [=========>....................] - ETA: 1:59 - loss: 4.7340 41/119 [=========>....................] - ETA: 1:57 - loss: 4.7268 42/119 [=========>....................] - ETA: 1:56 - loss: 4.6973 43/119 [=========>....................] - ETA: 1:54 - loss: 4.7000 44/119 [==========>...................] - ETA: 1:52 - loss: 4.6944 45/119 [==========>...................] - ETA: 1:51 - loss: 4.6894 46/119 [==========>...................] - ETA: 1:49 - loss: 4.6897 47/119 [==========>...................] - ETA: 1:48 - loss: 4.6684 48/119 [===========>..................] - ETA: 1:46 - loss: 4.6728 49/119 [===========>..................] - ETA: 1:45 - loss: 4.7095 50/119 [===========>..................] - ETA: 1:43 - loss: 4.6931 51/119 [===========>..................] - ETA: 1:42 - loss: 4.6844 52/119 [============>.................] - ETA: 1:40 - loss: 4.6625 53/119 [============>.................] - ETA: 1:39 - loss: 4.6995 54/119 [============>.................] - ETA: 1:37 - loss: 4.7191 55/119 [============>.................] - ETA: 1:35 - loss: 4.6957 56/119 [=============>................] - ETA: 1:34 - loss: 4.6574 57/119 [=============>................] - ETA: 1:32 - loss: 4.6335 58/119 [=============>................] - ETA: 1:31 - loss: 4.6284 59/119 [=============>................] - ETA: 1:30 - loss: 4.6031 60/119 [==============>...............] - ETA: 1:28 - loss: 4.6013 61/119 [==============>...............] - ETA: 1:27 - loss: 4.5915 62/119 [==============>...............] - ETA: 1:25 - loss: 4.5934 63/119 [==============>...............] - ETA: 1:24 - loss: 4.6387 64/119 [===============>..............] - ETA: 1:22 - loss: 4.6305 65/119 [===============>..............] - ETA: 1:20 - loss: 4.6133 66/119 [===============>..............] - ETA: 1:19 - loss: 4.6103 67/119 [===============>..............] - ETA: 1:17 - loss: 4.6286 68/119 [================>.............] - ETA: 1:16 - loss: 4.6093 69/119 [================>.............] - ETA: 1:15 - loss: 4.5836 70/119 [================>.............] - ETA: 1:13 - loss: 4.5713 71/119 [================>.............] - ETA: 1:12 - loss: 4.5556 72/119 [=================>............] - ETA: 1:10 - loss: 4.5462 73/119 [=================>............] - ETA: 1:09 - loss: 4.5438 74/119 [=================>............] - ETA: 1:07 - loss: 4.5022 75/119 [=================>............] - ETA: 1:06 - loss: 4.4813 76/119 [==================>...........] - ETA: 1:04 - loss: 4.4504 77/119 [==================>...........] - ETA: 1:03 - loss: 4.4537 78/119 [==================>...........] - ETA: 1:01 - loss: 4.4569 79/119 [==================>...........] - ETA: 1:00 - loss: 4.4471 80/119 [===================>..........] - ETA: 58s - loss: 4.4490  81/119 [===================>..........] - ETA: 57s - loss: 4.4390 82/119 [===================>..........] - ETA: 55s - loss: 4.4267 83/119 [===================>..........] - ETA: 54s - loss: 4.4125 84/119 [====================>.........] - ETA: 52s - loss: 4.4161 85/119 [====================>.........] - ETA: 51s - loss: 4.4117 86/119 [====================>.........] - ETA: 49s - loss: 4.4163 87/119 [====================>.........] - ETA: 48s - loss: 4.4224 88/119 [=====================>........] - ETA: 46s - loss: 4.4277 89/119 [=====================>........] - ETA: 45s - loss: 4.4298 90/119 [=====================>........] - ETA: 43s - loss: 4.4213 91/119 [=====================>........] - ETA: 42s - loss: 4.4356 92/119 [======================>.......] - ETA: 40s - loss: 4.4137 93/119 [======================>.......] - ETA: 39s - loss: 4.3962 94/119 [======================>.......] - ETA: 37s - loss: 4.4167 95/119 [======================>.......] - ETA: 36s - loss: 4.4165 96/119 [=======================>......] - ETA: 34s - loss: 4.4099 97/119 [=======================>......] - ETA: 33s - loss: 4.4093 98/119 [=======================>......] - ETA: 31s - loss: 4.3990 99/119 [=======================>......] - ETA: 29s - loss: 4.3975100/119 [========================>.....] - ETA: 28s - loss: 4.3846101/119 [========================>.....] - ETA: 26s - loss: 4.3694102/119 [========================>.....] - ETA: 25s - loss: 4.3637103/119 [========================>.....] - ETA: 23s - loss: 4.3646104/119 [=========================>....] - ETA: 22s - loss: 4.3494105/119 [=========================>....] - ETA: 20s - loss: 4.3479106/119 [=========================>....] - ETA: 19s - loss: 4.3333107/119 [=========================>....] - ETA: 17s - loss: 4.3123108/119 [==========================>...] - ETA: 16s - loss: 4.2829109/119 [==========================>...] - ETA: 14s - loss: 4.2958110/119 [==========================>...] - ETA: 13s - loss: 4.2951111/119 [==========================>...] - ETA: 11s - loss: 4.2886112/119 [===========================>..] - ETA: 10s - loss: 4.2740113/119 [===========================>..] - ETA: 8s - loss: 4.2573 114/119 [===========================>..] - ETA: 7s - loss: 4.2457115/119 [===========================>..] - ETA: 5s - loss: 4.2472116/119 [============================>.] - ETA: 4s - loss: 4.2318117/119 [============================>.] - ETA: 2s - loss: 4.2143118/119 [============================>.] - ETA: 1s - loss: 4.2103119/119 [==============================] - ETA: 0s - loss: 4.1954119/119 [==============================] - 252s 2s/step - loss: 4.1954 - val_loss: 2.6374
2021-10-25 17:22:46.380277: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
The temperature of the GPU is  46
Epoch 2/100
  1/119 [..............................] - ETA: 3:54 - loss: 2.2165  2/119 [..............................] - ETA: 2:31 - loss: 2.7467  3/119 [..............................] - ETA: 2:47 - loss: 2.6261  4/119 [>.............................] - ETA: 2:45 - loss: 2.9370  5/119 [>.............................] - ETA: 2:43 - loss: 3.2668  6/119 [>.............................] - ETA: 2:44 - loss: 3.1933  7/119 [>.............................] - ETA: 2:42 - loss: 3.1150  8/119 [=>............................] - ETA: 2:42 - loss: 3.1123  9/119 [=>............................] - ETA: 2:38 - loss: 3.1669 10/119 [=>............................] - ETA: 2:37 - loss: 3.0393 11/119 [=>............................] - ETA: 2:35 - loss: 2.9999 12/119 [==>...........................] - ETA: 2:34 - loss: 2.9625 13/119 [==>...........................] - ETA: 2:33 - loss: 3.1481 14/119 [==>...........................] - ETA: 2:32 - loss: 3.1162 15/119 [==>...........................] - ETA: 2:30 - loss: 3.0538 16/119 [===>..........................] - ETA: 2:28 - loss: 3.0268 17/119 [===>..........................] - ETA: 2:27 - loss: 3.0815 18/119 [===>..........................] - ETA: 2:26 - loss: 3.0272 19/119 [===>..........................] - ETA: 2:25 - loss: 2.9912 20/119 [====>.........................] - ETA: 2:23 - loss: 2.9730 21/119 [====>.........................] - ETA: 2:22 - loss: 2.9846 22/119 [====>.........................] - ETA: 2:20 - loss: 3.1168 23/119 [====>.........................] - ETA: 2:19 - loss: 3.0646 24/119 [=====>........................] - ETA: 2:17 - loss: 3.0323 25/119 [=====>........................] - ETA: 2:15 - loss: 3.0804 26/119 [=====>........................] - ETA: 2:14 - loss: 3.0748 27/119 [=====>........................] - ETA: 2:13 - loss: 3.0445 28/119 [======>.......................] - ETA: 2:11 - loss: 3.1421 29/119 [======>.......................] - ETA: 2:09 - loss: 3.1184 30/119 [======>.......................] - ETA: 2:08 - loss: 3.1119 31/119 [======>.......................] - ETA: 2:06 - loss: 3.1086 32/119 [=======>......................] - ETA: 2:05 - loss: 3.0781 33/119 [=======>......................] - ETA: 2:03 - loss: 3.1160 34/119 [=======>......................] - ETA: 2:01 - loss: 3.1125 35/119 [=======>......................] - ETA: 2:00 - loss: 3.1171 36/119 [========>.....................] - ETA: 1:58 - loss: 3.0944 37/119 [========>.....................] - ETA: 1:57 - loss: 3.0904 38/119 [========>.....................] - ETA: 1:56 - loss: 3.1521 39/119 [========>.....................] - ETA: 1:54 - loss: 3.1564 40/119 [=========>....................] - ETA: 1:53 - loss: 3.1619 41/119 [=========>....................] - ETA: 1:52 - loss: 3.1378 42/119 [=========>....................] - ETA: 1:50 - loss: 3.1099 43/119 [=========>....................] - ETA: 1:49 - loss: 3.0931 44/119 [==========>...................] - ETA: 1:47 - loss: 3.1618 45/119 [==========>...................] - ETA: 1:46 - loss: 3.1201 46/119 [==========>...................] - ETA: 1:44 - loss: 3.0993 47/119 [==========>...................] - ETA: 1:43 - loss: 3.0893 48/119 [===========>..................] - ETA: 1:41 - loss: 3.0782 49/119 [===========>..................] - ETA: 1:40 - loss: 3.0856 50/119 [===========>..................] - ETA: 1:38 - loss: 3.1198 51/119 [===========>..................] - ETA: 1:37 - loss: 3.1087 52/119 [============>.................] - ETA: 1:35 - loss: 3.1100 53/119 [============>.................] - ETA: 1:34 - loss: 3.1380 54/119 [============>.................] - ETA: 1:33 - loss: 3.1159 55/119 [============>.................] - ETA: 1:31 - loss: 3.0856 56/119 [=============>................] - ETA: 1:30 - loss: 3.0548 57/119 [=============>................] - ETA: 1:29 - loss: 3.0507 58/119 [=============>................] - ETA: 1:27 - loss: 3.0277 59/119 [=============>................] - ETA: 1:26 - loss: 3.0199 60/119 [==============>...............] - ETA: 1:24 - loss: 2.9965 61/119 [==============>...............] - ETA: 1:23 - loss: 2.9806 62/119 [==============>...............] - ETA: 1:22 - loss: 2.9867 63/119 [==============>...............] - ETA: 1:20 - loss: 2.9639 64/119 [===============>..............] - ETA: 1:19 - loss: 2.9871 65/119 [===============>..............] - ETA: 1:17 - loss: 2.9614 66/119 [===============>..............] - ETA: 1:16 - loss: 2.9592 67/119 [===============>..............] - ETA: 1:14 - loss: 2.9761 68/119 [================>.............] - ETA: 1:13 - loss: 2.9732 69/119 [================>.............] - ETA: 1:12 - loss: 2.9823 70/119 [================>.............] - ETA: 1:10 - loss: 3.0031 71/119 [================>.............] - ETA: 1:08 - loss: 2.9929 72/119 [=================>............] - ETA: 1:07 - loss: 2.9865 73/119 [=================>............] - ETA: 1:06 - loss: 3.0020 74/119 [=================>............] - ETA: 1:04 - loss: 2.9866 75/119 [=================>............] - ETA: 1:03 - loss: 3.0176 76/119 [==================>...........] - ETA: 1:01 - loss: 2.9997srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
srun: got SIGCONT
slurmstepd: error: *** JOB 796908 ON nodegpu002 CANCELLED AT 2021-10-25T17:24:52 ***
slurmstepd: error: *** STEP 796908.0 ON nodegpu002 CANCELLED AT 2021-10-25T17:24:52 ***
srun: forcing job termination
