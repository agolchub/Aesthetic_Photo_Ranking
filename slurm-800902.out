
CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.
To initialize your shell, run

    $ conda init <SHELL_NAME>

Currently supported shells are:
  - bash
  - fish
  - tcsh
  - xonsh
  - zsh
  - powershell

See 'conda init --help' for more information and options.

IMPORTANT: You may need to close and restart your shell after running 'conda init'.


Mon Nov  1 17:24:53 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  A100-PCIE-40GB      Off  | 00000000:21:00.0 Off |                    0 |
| N/A   52C    P0    43W / 250W |      0MiB / 40536MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
2021-11-01 17:25:14.315821: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-01 17:25:15.316229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38426 MB memory:  -> device: 0, name: A100-PCIE-40GB, pci bus id: 0000:21:00.0, compute capability: 8.0
/mnt/beegfs/home/agolchub/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  warnings.warn(
Input file is " 
Output file is " agnet.specialmodel2.3.batchnormalization.meadowsonly
Image path is " 
--------------------


Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 1024, 680, 3 0                                            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 336, 338, 80) 26000       input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 336, 338, 80) 320         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 336, 338, 80) 0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 336, 338, 80) 0           activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 164, 165, 80) 518480      dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 164, 165, 80) 320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 164, 165, 80) 0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 164, 165, 80) 0           activation_7[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 79, 80, 160)  627360      dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 79, 80, 160)  640         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 79, 80, 160)  0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 79, 80, 160)  0           activation_10[0][0]              
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 989, 669, 48) 62256       input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 38, 38, 160)  640160      dropout_10[0][0]                 
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 989, 669, 48) 192         conv2d[0][0]                     
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 38, 38, 160)  640         conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation (Activation)         (None, 989, 669, 48) 0           batch_normalization[0][0]        
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 38, 38, 160)  0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout (Dropout)               (None, 989, 669, 48) 0           activation[0][0]                 
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 38, 38, 160)  0           activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 491, 331, 80) 311120      dropout[0][0]                    
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 19, 19, 320)  205120      dropout_13[0][0]                 
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 491, 331, 80) 320         conv2d_1[0][0]                   
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 19, 19, 320)  1280        conv2d_16[0][0]                  
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 491, 331, 80) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 19, 19, 320)  0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 491, 331, 80) 0           activation_1[0][0]               
__________________________________________________________________________________________________
dropout_16 (Dropout)            (None, 19, 19, 320)  0           activation_16[0][0]              
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 245, 165, 80) 57680       dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 164, 165, 80) 518480      dropout_4[0][0]                  
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 80, 81, 160)  320160      dropout_7[0][0]                  
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 37, 37, 160)  1254560     dropout_10[0][0]                 
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 18, 18, 320)  461120      dropout_13[0][0]                 
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 9, 9, 320)    409920      dropout_16[0][0]                 
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 9, 9, 320)    409920      dropout_16[0][0]                 
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 245, 165, 80) 320         conv2d_2[0][0]                   
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 164, 165, 80) 320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 80, 81, 160)  640         conv2d_8[0][0]                   
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 37, 37, 160)  640         conv2d_11[0][0]                  
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 18, 18, 320)  1280        conv2d_14[0][0]                  
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 9, 9, 320)    1280        conv2d_17[0][0]                  
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 9, 9, 320)    1280        conv2d_19[0][0]                  
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 245, 165, 80) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 164, 165, 80) 0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 80, 81, 160)  0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 37, 37, 160)  0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 18, 18, 320)  0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 9, 9, 320)    0           batch_normalization_17[0][0]     
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 9, 9, 320)    0           batch_normalization_19[0][0]     
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 245, 165, 80) 0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 164, 165, 80) 0           activation_5[0][0]               
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 80, 81, 160)  0           activation_8[0][0]               
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 37, 37, 160)  0           activation_11[0][0]              
__________________________________________________________________________________________________
dropout_14 (Dropout)            (None, 18, 18, 320)  0           activation_14[0][0]              
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 9, 9, 320)    0           activation_17[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 9, 9, 320)    0           activation_19[0][0]              
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 122, 82, 80)  25680       dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 78, 79, 160)  1036960     dropout_5[0][0]                  
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 38, 39, 320)  1280320     dropout_8[0][0]                  
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 16, 16, 320)  2509120     dropout_11[0][0]                 
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 8, 8, 320)    921920      dropout_14[0][0]                 
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 4, 4, 320)    409920      dropout_17[0][0]                 
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 4, 4, 320)    409920      dropout_19[0][0]                 
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 122, 82, 80)  320         conv2d_3[0][0]                   
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 78, 79, 160)  640         conv2d_6[0][0]                   
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 38, 39, 320)  1280        conv2d_9[0][0]                   
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 16, 16, 320)  1280        conv2d_12[0][0]                  
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 8, 8, 320)    1280        conv2d_15[0][0]                  
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 4, 4, 320)    1280        conv2d_18[0][0]                  
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 4, 4, 320)    1280        conv2d_20[0][0]                  
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 122, 82, 80)  0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 78, 79, 160)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 38, 39, 320)  0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 16, 16, 320)  0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 8, 8, 320)    0           batch_normalization_15[0][0]     
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 4, 4, 320)    0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 4, 4, 320)    0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 122, 82, 80)  0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 78, 79, 160)  0           activation_6[0][0]               
__________________________________________________________________________________________________
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
srun: got SIGCONT
slurmstepd: error: *** STEP 800902.0 ON nodegpu002 CANCELLED AT 2021-11-01T17:25:16 ***
slurmstepd: error: *** JOB 800902 ON nodegpu002 CANCELLED AT 2021-11-01T17:25:16 ***
srun: forcing job termination
