
CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.
To initialize your shell, run

    $ conda init <SHELL_NAME>

Currently supported shells are:
  - bash
  - fish
  - tcsh
  - xonsh
  - zsh
  - powershell

See 'conda init --help' for more information and options.

IMPORTANT: You may need to close and restart your shell after running 'conda init'.


Mon Oct 25 03:19:48 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  A100-PCIE-40GB      Off  | 00000000:21:00.0 Off |                    0 |
| N/A   44C    P0    41W / 250W |      0MiB / 40536MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
2021-10-25 03:20:00.985901: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-10-25 03:20:01.807385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38426 MB memory:  -> device: 0, name: A100-PCIE-40GB, pci bus id: 0000:21:00.0, compute capability: 8.0
2021-10-25 03:20:02.402767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38426 MB memory:  -> device: 0, name: A100-PCIE-40GB, pci bus id: 0000:21:00.0, compute capability: 8.0
/mnt/beegfs/home/agolchub/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  warnings.warn(
Input file is " 
Output file is " agnet-wide.model
Image path is " 
--------------------


input_1  re-initilized
initializing kernel weights
conv2d  could not be re-initilized (<class 'AttributeError'>, AttributeError("'NoneType' object has no attribute 'run'"), <traceback object at 0x7f82a03bdcc0>)
batch_normalization  re-initilized
dropout  re-initilized
initializing kernel weights
conv2d_2  could not be re-initilized (<class 'AttributeError'>, AttributeError("'NoneType' object has no attribute 'run'"), <traceback object at 0x7f82a03c0800>)
batch_normalization_2  re-initilized
dropout_2  re-initilized
initializing kernel weights
conv2d_4  could not be re-initilized (<class 'AttributeError'>, AttributeError("'NoneType' object has no attribute 'run'"), <traceback object at 0x7f82a03bd080>)
batch_normalization_4  re-initilized
dropout_4  re-initilized
initializing kernel weights
conv2d_6  could not be re-initilized (<class 'AttributeError'>, AttributeError("'NoneType' object has no attribute 'run'"), <traceback object at 0x7f82a03c04c0>)
batch_normalization_6  re-initilized
dropout_6  re-initilized
initializing kernel weights
conv2d_8  could not be re-initilized (<class 'AttributeError'>, AttributeError("'NoneType' object has no attribute 'run'"), <traceback object at 0x7f82a03bdcc0>)
batch_normalization_8  re-initilized
dropout_8  re-initilized
initializing kernel weights
conv2d_10  could not be re-initilized (<class 'AttributeError'>, AttributeError("'NoneType' object has no attribute 'run'"), <traceback object at 0x7f82a03c0800>)
batch_normalization_10  re-initilized
dropout_10  re-initilized
initializing kernel weights
conv2d_12  could not be re-initilized (<class 'AttributeError'>, AttributeError("'NoneType' object has no attribute 'run'"), <traceback object at 0x7f82a03bd080>)
batch_normalization_12  re-initilized
dropout_12  re-initilized
initializing kernel weights
conv2d_14  could not be re-initilized (<class 'AttributeError'>, AttributeError("'NoneType' object has no attribute 'run'"), <traceback object at 0x7f82a03c04c0>)
batch_normalization_14  re-initilized
dropout_14  re-initilized
initializing kernel weights
conv2d_1  could not be re-initilized (<class 'AttributeError'>, AttributeError("'NoneType' object has no attribute 'run'"), <traceback object at 0x7f82a03bdcc0>)
initializing kernel weights
conv2d_3  could not be re-initilized (<class 'AttributeError'>, AttributeError("'NoneType' object has no attribute 'run'"), <traceback object at 0x7f82a03c04c0>)
initializing kernel weights
conv2d_5  could not be re-initilized (<class 'AttributeError'>, AttributeError("'NoneType' object has no attribute 'run'"), <traceback object at 0x7f82a03bd080>)
initializing kernel weights
conv2d_7  could not be re-initilized (<class 'AttributeError'>, AttributeError("'NoneType' object has no attribute 'run'"), <traceback object at 0x7f82a03c0800>)
initializing kernel weights
conv2d_9  could not be re-initilized (<class 'AttributeError'>, AttributeError("'NoneType' object has no attribute 'run'"), <traceback object at 0x7f82a03bdcc0>)
initializing kernel weights
conv2d_11  could not be re-initilized (<class 'AttributeError'>, AttributeError("'NoneType' object has no attribute 'run'"), <traceback object at 0x7f82a03c04c0>)
initializing kernel weights
conv2d_13  could not be re-initilized (<class 'AttributeError'>, AttributeError("'NoneType' object has no attribute 'run'"), <traceback object at 0x7f82a03bd080>)
initializing kernel weights
conv2d_15  could not be re-initilized (<class 'AttributeError'>, AttributeError("'NoneType' object has no attribute 'run'"), <traceback object at 0x7f82a03c0800>)
initializing kernel weights
conv2d_16  could not be re-initilized (<class 'AttributeError'>, AttributeError("'NoneType' object has no attribute 'run'"), <traceback object at 0x7f82a03bdcc0>)
batch_normalization_1  re-initilized
batch_normalization_3  re-initilized
batch_normalization_5  re-initilized
batch_normalization_7  re-initilized
batch_normalization_9  re-initilized
batch_normalization_11  re-initilized
batch_normalization_13  re-initilized
batch_normalization_15  re-initilized
batch_normalization_16  re-initilized
dropout_1  re-initilized
dropout_3  re-initilized
dropout_5  re-initilized
dropout_7  re-initilized
dropout_9  re-initilized
dropout_11  re-initilized
dropout_13  re-initilized
dropout_15  re-initilized
dropout_16  re-initilized
flatten  re-initilized
flatten_1  re-initilized
flatten_2  re-initilized
flatten_3  re-initilized
flatten_4  re-initilized
flatten_5  re-initilized
flatten_6  re-initilized
flatten_7  re-initilized
flatten_8  re-initilized
initializing kernel weights
dense  could not be re-initilized (<class 'AttributeError'>, AttributeError("'NoneType' object has no attribute 'run'"), <traceback object at 0x7f82a03bdcc0>)
initializing kernel weights
dense_1  could not be re-initilized (<class 'AttributeError'>, AttributeError("'NoneType' object has no attribute 'run'"), <traceback object at 0x7f82a03c04c0>)
initializing kernel weights
dense_2  could not be re-initilized (<class 'AttributeError'>, AttributeError("'NoneType' object has no attribute 'run'"), <traceback object at 0x7f82a03bd080>)
initializing kernel weights
dense_3  could not be re-initilized (<class 'AttributeError'>, AttributeError("'NoneType' object has no attribute 'run'"), <traceback object at 0x7f82a03c0800>)
initializing kernel weights
dense_4  could not be re-initilized (<class 'AttributeError'>, AttributeError("'NoneType' object has no attribute 'run'"), <traceback object at 0x7f82a03bdcc0>)
initializing kernel weights
dense_5  could not be re-initilized (<class 'AttributeError'>, AttributeError("'NoneType' object has no attribute 'run'"), <traceback object at 0x7f82a03c04c0>)
initializing kernel weights
dense_6  could not be re-initilized (<class 'AttributeError'>, AttributeError("'NoneType' object has no attribute 'run'"), <traceback object at 0x7f82a03bd080>)
initializing kernel weights
dense_7  could not be re-initilized (<class 'AttributeError'>, AttributeError("'NoneType' object has no attribute 'run'"), <traceback object at 0x7f82a03c0800>)
initializing kernel weights
dense_8  could not be re-initilized (<class 'AttributeError'>, AttributeError("'NoneType' object has no attribute 'run'"), <traceback object at 0x7f82a03bdcc0>)
concatenate  re-initilized
initializing kernel weights
dense_9  could not be re-initilized (<class 'AttributeError'>, AttributeError("'NoneType' object has no attribute 'run'"), <traceback object at 0x7f82a03bd080>)
dropout_17  re-initilized
initializing kernel weights
dense_10  could not be re-initilized (<class 'AttributeError'>, AttributeError("'NoneType' object has no attribute 'run'"), <traceback object at 0x7f82a03bdcc0>)
dropout_18  re-initilized
initializing kernel weights
dense_11  could not be re-initilized (<class 'AttributeError'>, AttributeError("'NoneType' object has no attribute 'run'"), <traceback object at 0x7f82a03bd080>)
initializing kernel weights
dense_12  could not be re-initilized (<class 'AttributeError'>, AttributeError("'NoneType' object has no attribute 'run'"), <traceback object at 0x7f82a03c0800>)
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 1024, 680, 3 0                                            
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 298, 297, 32) 1115168     input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 298, 297, 32) 128         conv2d[0][0]                     
__________________________________________________________________________________________________
dropout (Dropout)               (None, 298, 297, 32) 0           batch_normalization[0][0]        
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 117, 116, 64) 8921152     dropout[0][0]                    
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 117, 116, 64) 256         conv2d_2[0][0]                   
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 117, 116, 64) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 51, 51, 128)  2097280     dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 51, 51, 128)  512         conv2d_4[0][0]                   
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 51, 51, 128)  0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 23, 23, 256)  1605888     dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 23, 23, 256)  1024        conv2d_6[0][0]                   
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 23, 23, 256)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 21, 21, 512)  1180160     dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 21, 21, 512)  2048        conv2d_8[0][0]                   
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 21, 21, 512)  0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 20, 20, 256)  524544      dropout_8[0][0]                  
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 20, 20, 256)  1024        conv2d_10[0][0]                  
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 20, 20, 256)  0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 19, 19, 128)  131200      dropout_10[0][0]                 
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 19, 19, 128)  512         conv2d_12[0][0]                  
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 19, 19, 128)  0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 18, 18, 64)   32832       dropout_12[0][0]                 
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 18, 18, 64)   256         conv2d_14[0][0]                  
__________________________________________________________________________________________________
dropout_14 (Dropout)            (None, 18, 18, 64)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 266, 265, 64) 2230336     dropout[0][0]                    
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 102, 101, 64) 1048640     dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 36, 36, 64)   2097216     dropout_4[0][0]                  
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 17, 17, 64)   802880      dropout_6[0][0]                  
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 19, 19, 64)   294976      dropout_8[0][0]                  
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 19, 19, 64)   65600       dropout_10[0][0]                 
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 18, 18, 64)   32832       dropout_12[0][0]                 
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 17, 17, 64)   16448       dropout_14[0][0]                 
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 17, 17, 32)   8224        dropout_14[0][0]                 
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 266, 265, 64) 256         conv2d_1[0][0]                   
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 102, 101, 64) 256         conv2d_3[0][0]                   
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 36, 36, 64)   256         conv2d_5[0][0]                   
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 17, 17, 64)   256         conv2d_7[0][0]                   
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 19, 19, 64)   256         conv2d_9[0][0]                   
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 19, 19, 64)   256         conv2d_11[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 18, 18, 64)   256         conv2d_13[0][0]                  
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 17, 17, 64)   256         conv2d_15[0][0]                  
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 17, 17, 32)   128         conv2d_16[0][0]                  
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 266, 265, 64) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 102, 101, 64) 0           batch_normalization_3[0][0]      
/mnt/beegfs/home/agolchub/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.
  warnings.warn('`Model.fit_generator` is deprecated and '
2021-10-25 03:20:08.608366: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
2021-10-25 03:20:17.563910: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8201
2021-10-25 03:20:20.229486: W tensorflow/stream_executor/gpu/asm_compiler.cc:77] Couldn't get ptxas version string: Internal: Running ptxas --version returned 32512
2021-10-25 03:20:20.292570: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 32512, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
2021-10-25 03:21:12.638496: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 36, 36, 64)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 17, 17, 64)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 19, 19, 64)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 19, 19, 64)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 18, 18, 64)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_15 (Dropout)            (None, 17, 17, 64)   0           batch_normalization_15[0][0]     
__________________________________________________________________________________________________
dropout_16 (Dropout)            (None, 17, 17, 32)   0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
flatten (Flatten)               (None, 4511360)      0           dropout_1[0][0]                  
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 659328)       0           dropout_3[0][0]                  
__________________________________________________________________________________________________
flatten_2 (Flatten)             (None, 82944)        0           dropout_5[0][0]                  
__________________________________________________________________________________________________
flatten_3 (Flatten)             (None, 18496)        0           dropout_7[0][0]                  
__________________________________________________________________________________________________
flatten_4 (Flatten)             (None, 23104)        0           dropout_9[0][0]                  
__________________________________________________________________________________________________
flatten_5 (Flatten)             (None, 23104)        0           dropout_11[0][0]                 
__________________________________________________________________________________________________
flatten_6 (Flatten)             (None, 20736)        0           dropout_13[0][0]                 
__________________________________________________________________________________________________
flatten_7 (Flatten)             (None, 18496)        0           dropout_15[0][0]                 
__________________________________________________________________________________________________
flatten_8 (Flatten)             (None, 9248)         0           dropout_16[0][0]                 
__________________________________________________________________________________________________
dense (Dense)                   (None, 25)           112784025   flatten[0][0]                    
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 25)           16483225    flatten_1[0][0]                  
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 25)           2073625     flatten_2[0][0]                  
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 25)           462425      flatten_3[0][0]                  
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 25)           577625      flatten_4[0][0]                  
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 25)           577625      flatten_5[0][0]                  
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 25)           518425      flatten_6[0][0]                  
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 25)           462425      flatten_7[0][0]                  
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 128)          1183872     flatten_8[0][0]                  
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 328)          0           dense[0][0]                      
                                                                 dense_1[0][0]                    
                                                                 dense_2[0][0]                    
                                                                 dense_3[0][0]                    
                                                                 dense_4[0][0]                    
                                                                 dense_5[0][0]                    
                                                                 dense_6[0][0]                    
                                                                 dense_7[0][0]                    
                                                                 dense_8[0][0]                    
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 256)          84224       concatenate[0][0]                
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 256)          0           dense_9[0][0]                    
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 128)          32896       dropout_17[0][0]                 
__________________________________________________________________________________________________
dropout_18 (Dropout)            (None, 128)          0           dense_10[0][0]                   
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 10)           1290        dropout_18[0][0]                 
__________________________________________________________________________________________________
dense_12 (Dense)                (None, 1)            11          dense_11[0][0]                   
==================================================================================================
Total params: 157,455,005
Trainable params: 157,451,037
Non-trainable params: 3,968
__________________________________________________________________________________________________
None
Epoch 1/100
 1/23 [>.............................] - ETA: 41:47 - loss: 10.2938 2/23 [=>............................] - ETA: 1:27 - loss: 8.4815   3/23 [==>...........................] - ETA: 2:03 - loss: 8.5660 4/23 [====>.........................] - ETA: 2:06 - loss: 7.9596 5/23 [=====>........................] - ETA: 2:04 - loss: 7.2000 6/23 [======>.......................] - ETA: 1:58 - loss: 7.1627 7/23 [========>.....................] - ETA: 1:54 - loss: 6.8038 8/23 [=========>....................] - ETA: 1:49 - loss: 6.6350 9/23 [==========>...................] - ETA: 1:42 - loss: 6.593610/23 [============>.................] - ETA: 1:36 - loss: 6.514011/23 [=============>................] - ETA: 1:29 - loss: 6.504912/23 [==============>...............] - ETA: 1:21 - loss: 6.396813/23 [===============>..............] - ETA: 1:14 - loss: 6.268314/23 [=================>............] - ETA: 1:07 - loss: 6.128415/23 [==================>...........] - ETA: 1:00 - loss: 6.016916/23 [===================>..........] - ETA: 52s - loss: 5.9580 17/23 [=====================>........] - ETA: 45s - loss: 5.843218/23 [======================>.......] - ETA: 37s - loss: 5.712419/23 [=======================>......] - ETA: 30s - loss: 5.637120/23 [=========================>....] - ETA: 22s - loss: 5.527121/23 [==========================>...] - ETA: 15s - loss: 5.441522/23 [===========================>..] - ETA: 7s - loss: 5.3554 23/23 [==============================] - ETA: 0s - loss: 5.310023/23 [==============================] - 334s 10s/step - loss: 5.3100 - val_loss: 11.4729
The temperature of the GPU is  46
Epoch 2/100
 1/23 [>.............................] - ETA: 3:56 - loss: 4.1715 2/23 [=>............................] - ETA: 2:29 - loss: 3.7716 3/23 [==>...........................] - ETA: 2:32 - loss: 4.0388 4/23 [====>.........................] - ETA: 2:21 - loss: 4.4098 5/23 [=====>........................] - ETA: 2:15 - loss: 4.4170 6/23 [======>.......................] - ETA: 2:08 - loss: 4.5817 7/23 [========>.....................] - ETA: 2:00 - loss: 4.5933 8/23 [=========>....................] - ETA: 1:53 - loss: 4.4909 9/23 [==========>...................] - ETA: 1:46 - loss: 4.659610/23 [============>.................] - ETA: 1:39 - loss: 4.717011/23 [=============>................] - ETA: 1:31 - loss: 4.587312/23 [==============>...............] - ETA: 1:24 - loss: 4.766813/23 [===============>..............] - ETA: 1:16 - loss: 4.737214/23 [=================>............] - ETA: 1:09 - loss: 4.604715/23 [==================>...........] - ETA: 1:01 - loss: 4.563716/23 [===================>..........] - ETA: 54s - loss: 4.6384 17/23 [=====================>........] - ETA: 46s - loss: 4.558318/23 [======================>.......] - ETA: 38s - loss: 4.554919/23 [=======================>......] - ETA: 30s - loss: 4.488820/23 [=========================>....] - ETA: 23s - loss: 4.429021/23 [==========================>...] - ETA: 15s - loss: 4.352622/23 [===========================>..] - ETA: 7s - loss: 4.2823 23/23 [==============================] - ETA: 0s - loss: 4.239423/23 [==============================] - 227s 10s/step - loss: 4.2394 - val_loss: 4.1618
The temperature of the GPU is  45
Epoch 3/100
 1/23 [>.............................] - ETA: 3:48 - loss: 3.0452 2/23 [=>............................] - ETA: 2:50 - loss: 3.3480 3/23 [==>...........................] - ETA: 2:41 - loss: 3.2278 4/23 [====>.........................] - ETA: 2:30 - loss: 3.1732 5/23 [=====>........................] - ETA: 2:21 - loss: 3.1033 6/23 [======>.......................] - ETA: 2:14 - loss: 3.0401 7/23 [========>.....................] - ETA: 2:06 - loss: 3.0519 8/23 [=========>....................] - ETA: 1:57 - loss: 3.0892 9/23 [==========>...................] - ETA: 1:48 - loss: 3.168810/23 [============>.................] - ETA: 1:40 - loss: 3.145711/23 [=============>................] - ETA: 1:32 - loss: 3.098612/23 [==============>...............] - ETA: 1:24 - loss: 3.115713/23 [===============>..............] - ETA: 1:17 - loss: 3.176114/23 [=================>............] - ETA: 1:09 - loss: 3.207415/23 [==================>...........] - ETA: 1:01 - loss: 3.211316/23 [===================>..........] - ETA: 54s - loss: 3.1556 srun: got SIGCONT
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** JOB 796726 ON nodegpu002 CANCELLED AT 2021-10-25T03:34:39 ***
srun: forcing job termination
slurmstepd: error: *** STEP 796726.0 ON nodegpu002 CANCELLED AT 2021-10-25T03:34:39 ***
