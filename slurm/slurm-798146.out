
CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.
To initialize your shell, run

    $ conda init <SHELL_NAME>

Currently supported shells are:
  - bash
  - fish
  - tcsh
  - xonsh
  - zsh
  - powershell

See 'conda init --help' for more information and options.

IMPORTANT: You may need to close and restart your shell after running 'conda init'.


Wed Oct 27 20:20:30 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  A100-PCIE-40GB      Off  | 00000000:21:00.0 Off |                    0 |
| N/A   37C    P0    39W / 250W |      0MiB / 40536MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
2021-10-27 20:20:41.947116: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-10-27 20:20:42.739812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38426 MB memory:  -> device: 0, name: A100-PCIE-40GB, pci bus id: 0000:21:00.0, compute capability: 8.0
/mnt/beegfs/home/agolchub/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  warnings.warn(
Input file is " 
Output file is " agnet.specialmodel2.newbinary
Image path is " 
--------------------


Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 1024, 680, 3 0                                            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 336, 338, 48) 15600       input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 336, 338, 48) 192         conv2d_4[0][0]                   
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 336, 338, 48) 0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 164, 165, 80) 311120      dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 164, 165, 80) 320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 164, 165, 80) 0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 79, 80, 160)  627360      dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 79, 80, 160)  640         conv2d_10[0][0]                  
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 79, 80, 160)  0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 989, 669, 48) 62256       input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 38, 38, 160)  640160      dropout_10[0][0]                 
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 989, 669, 48) 192         conv2d[0][0]                     
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 38, 38, 160)  640         conv2d_13[0][0]                  
__________________________________________________________________________________________________
dropout (Dropout)               (None, 989, 669, 48) 0           batch_normalization[0][0]        
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 38, 38, 160)  0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 491, 331, 80) 311120      dropout[0][0]                    
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 19, 19, 320)  205120      dropout_13[0][0]                 
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 491, 331, 80) 320         conv2d_1[0][0]                   
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 19, 19, 320)  1280        conv2d_16[0][0]                  
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 491, 331, 80) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_16 (Dropout)            (None, 19, 19, 320)  0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 245, 165, 80) 57680       dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 164, 165, 80) 311120      dropout_4[0][0]                  
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 80, 81, 160)  320160      dropout_7[0][0]                  
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 37, 37, 320)  2509120     dropout_10[0][0]                 
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 18, 18, 320)  461120      dropout_13[0][0]                 
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 9, 9, 320)    409920      dropout_16[0][0]                 
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 9, 9, 320)    409920      dropout_16[0][0]                 
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 245, 165, 80) 320         conv2d_2[0][0]                   
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 164, 165, 80) 320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 80, 81, 160)  640         conv2d_8[0][0]                   
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 37, 37, 320)  1280        conv2d_11[0][0]                  
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 18, 18, 320)  1280        conv2d_14[0][0]                  
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 9, 9, 320)    1280        conv2d_17[0][0]                  
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 9, 9, 320)    1280        conv2d_19[0][0]                  
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 245, 165, 80) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 164, 165, 80) 0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 80, 81, 160)  0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 37, 37, 320)  0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
dropout_14 (Dropout)            (None, 18, 18, 320)  0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 9, 9, 320)    0           batch_normalization_17[0][0]     
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 9, 9, 320)    0           batch_normalization_19[0][0]     
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 122, 82, 80)  25680       dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 78, 79, 160)  1036960     dropout_5[0][0]                  
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 38, 39, 320)  1280320     dropout_8[0][0]                  
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 16, 16, 320)  5017920     dropout_11[0][0]                 
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 8, 8, 320)    921920      dropout_14[0][0]                 
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 4, 4, 320)    409920      dropout_17[0][0]                 
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 4, 4, 320)    409920      dropout_19[0][0]                 
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 122, 82, 80)  320         conv2d_3[0][0]                   
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 78, 79, 160)  640         conv2d_6[0][0]                   
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 38, 39, 320)  1280        conv2d_9[0][0]                   
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 16, 16, 320)  1280        conv2d_12[0][0]                  
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 8, 8, 320)    1280        conv2d_15[0][0]                  
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 4, 4, 320)    1280        conv2d_18[0][0]                  
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 4, 4, 320)    1280        conv2d_20[0][0]                  
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 122, 82, 80)  0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 78, 79, 160)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 38, 39, 320)  0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 16, 16, 320)  0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_15 (Dropout)            (None, 8, 8, 320)    0           batch_normalization_15[0][0]     
__________________________________________________________________________________________________
dropout_18 (Dropout)            (None, 4, 4, 320)    0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
dropout_20 (Dropout)            (None, 4, 4, 320)    0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
flatten (Flatten)               (None, 800320)       0           dropout_3[0][0]                  
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 985920)       0           dropout_6[0][0]                  
__________________________________________________________________________________________________
flatten_2 (Flatten)             (None, 474240)       0           dropout_9[0][0]                  
__________________________________________________________________________________________________
flatten_3 (Flatten)             (None, 81920)        0           dropout_12[0][0]                 
__________________________________________________________________________________________________
flatten_4 (Flatten)             (None, 20480)        0           dropout_15[0][0]                 
__________________________________________________________________________________________________
flatten_5 (Flatten)             (None, 5120)         0           dropout_18[0][0]                 
__________________________________________________________________________________________________
flatten_6 (Flatten)             (None, 5120)         0           dropout_20[0][0]                 
__________________________________________________________________________________________________
dense (Dense)                   (None, 128)          102441088   flatten[0][0]                    
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 25)           24648025    flatten_1[0][0]                  
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 25)           11856025    flatten_2[0][0]                  
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 25)           2048025     flatten_3[0][0]                  
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 25)           512025      flatten_4[0][0]                  
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 25)           128025      flatten_5[0][0]                  
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 25)           128025      flatten_6[0][0]                  
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 278)          0           dense[0][0]                      
                                                                 dense_1[0][0]                    
                                                                 dense_2[0][0]                    
                                                                 dense_3[0][0]                    
                                                                 dense_4[0][0]                    
                                                                 dense_5[0][0]                    
                                                                 dense_6[0][0]                    
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 256)          71424       concatenate[0][0]                
__________________________________________________________________________________________________
dropout_26 (Dropout)            (None, 256)          0           dense_10[0][0]                   
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 128)          32896       dropout_26[0][0]                 
__________________________________________________________________________________________________
dropout_27 (Dropout)            (None, 128)          0           dense_11[0][0]                   
__________________________________________________________________________________________________
dense_12 (Dense)                (None, 10)           1290        dropout_27[0][0]                 
__________________________________________________________________________________________________
dense_13 (Dense)                (None, 2)            22          dense_12[0][0]                   
==================================================================================================
Total params: 157,638,630
Trainable params: 157,629,958
Non-trainable params: 8,672
__________________________________________________________________________________________________
None
Adding Images: Reading ./databaserelease2/NatureDataset4/train2/0-meadows238.jpg
Traceback (most recent call last):
  File "/mnt/beegfs/home/agolchub/repo/Aesthetic_Photo_Ranking/./train.py", line 642, in <module>
    main(sys.argv[1:])
  File "/mnt/beegfs/home/agolchub/repo/Aesthetic_Photo_Ranking/./train.py", line 639, in main
    train(modelin,modelout,imagepath,epochs,batch_size,lr,decay,nesterov,checkpoint_filepath,train_path,val_path,transfer_learning,randomize_weights,use_resnet,special_model,build_only,special_model2,batched_reader,simple_model)
  File "/mnt/beegfs/home/agolchub/repo/Aesthetic_Photo_Ranking/./train.py", line 498, in train
    X_train,y_train,image_list_train = proc_image_dir(train_path)
  File "/mnt/beegfs/home/agolchub/repo/Aesthetic_Photo_Ranking/./train.py", line 131, in proc_image_dir
    out[rawscore-1] = 1
TypeError: list indices must be integers or slices, not float
srun: error: nodegpu002: task 0: Exited with exit code 1
